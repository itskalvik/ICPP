{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff215a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import numpy as np\n",
    "import gpflow\n",
    "gpflow.config.set_default_float(np.float32)\n",
    "from shapely import geometry\n",
    "import pointpats\n",
    "import shapely\n",
    "from time import time\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from sgptools.utils.tsp import run_tsp # TSP/VRP solver for initial path planning\n",
    "from sgptools.objectives import *\n",
    "from sgptools.methods import get_method\n",
    "from sgptools.kernels import get_kernel\n",
    "from sgptools.kernels.attentive import *\n",
    "from sgptools.utils.gpflow import get_model_params\n",
    "from sgptools.utils.data import Dataset\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "np.random.seed(1234)\n",
    "tf.random.set_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f266adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to extract lengthscales map from attentive non stationary kernel\n",
    "def predict_lengthscales(X, lengthscales, kernel):\n",
    "        preds = np.zeros(len(X))\n",
    "        repre1 = kernel.get_representations(X)\n",
    "        for i in range(len(lengthscales)):\n",
    "                attention = tf.tensordot(repre1[:, i],\n",
    "                                         tf.transpose(repre1[:, i]),\n",
    "                                         axes=0)\n",
    "                preds += np.diag(attention) * lengthscales[i]\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9edd943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = np.load(\"N17E073.npy\")\n",
    "plt.imshow(data.T, origin=\"lower\")\n",
    "plt.show()\n",
    "\n",
    "dataset = Dataset(data=data, dtype=np.float32,\n",
    "                  num_train=5000, num_test=20000)\n",
    "X_train, y_train = dataset.get_train()\n",
    "x_max, y_max = X_train.max(axis=0)\n",
    "x_min, y_min = X_train.min(axis=0)\n",
    "env = geometry.Polygon([[x_max, y_max], [x_min, y_max], [x_min, y_min], [x_max, y_min]])\n",
    "\n",
    "lengthscales = np.linspace(1, 10, 10)\n",
    "\n",
    "# Train GP/Kernel \n",
    "_, noise_variance, kernel, model = get_model_params(\n",
    "    X_train=X_train, y_train=y_train, \n",
    "    kernel=get_kernel('Attentive')(lengthscales=lengthscales),\n",
    "    optimizer='tf.Nadam',\n",
    "    learning_rate=1e-2,\n",
    "    max_steps=1000,\n",
    "    return_model=True,\n",
    "    verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4a0fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot GP prediction and lengthscale map\n",
    "X_test, _ = dataset.get_test()\n",
    "grid_x, grid_y = np.mgrid[min(X_test[:, 0]):max(X_test[:, 0]):100j, \n",
    "                          min(X_test[:, 1]):max(X_test[:, 1]):100j]\n",
    "X_test = np.stack([grid_x, grid_y], axis=-1)\n",
    "x_dim, y_dim = X_test.shape[:2]\n",
    "X_test = X_test.reshape(-1, 2).astype(X_train.dtype)\n",
    "\n",
    "mean, std = model.predict_f(X_test)\n",
    "lengthscale_preds = predict_lengthscales(X_test, lengthscales, kernel)\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5), constrained_layout=True)\n",
    "\n",
    "# First subplot — training data\n",
    "sc1 = axes[0].imshow(mean.numpy().reshape(x_dim, y_dim).T, origin=\"lower\")\n",
    "axes[0].set_title(\"GP Predictions\")\n",
    "axes[0].set_aspect('equal')\n",
    "\n",
    "# Second subplot — test data\n",
    "sc2 = axes[1].imshow(lengthscale_preds.reshape(x_dim, y_dim).T, origin=\"lower\")\n",
    "axes[1].set_title(\"Lengthscale Predictions\")\n",
    "axes[1].set_aspect('equal')\n",
    "\n",
    "# Shared colorbar\n",
    "fig.colorbar(sc2, ax=axes, orientation='vertical', \n",
    "             fraction=0.05, pad=0.04, label='Lengthscale')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5014fc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get contour\n",
    "grid_x, grid_y = X_test.reshape(x_dim, y_dim, 2)[:, :, 0], X_test.reshape(x_dim, y_dim, 2)[:, :, 1]\n",
    "grid_z = lengthscale_preds.reshape(x_dim, y_dim)\n",
    "cs = plt.contourf(grid_x, grid_y, grid_z, levels=1)\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b50da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract each polygon with holes from the contour map\n",
    "polygons = []\n",
    "levels = []\n",
    "for contour_path, level in zip(cs.get_paths(), [2, 4, 8]): \n",
    "    for idx, cp in enumerate(contour_path.to_polygons()):\n",
    "        x = cp[:,0]\n",
    "        y = cp[:,1]\n",
    "        polygon = geometry.Polygon([(i[0], i[1]) for i in zip(x,y)])\n",
    "\n",
    "        if idx == 0:\n",
    "            polygons.append(polygon)\n",
    "            levels.append(level)\n",
    "        else:\n",
    "            if polygons[-1].intersects(polygon):\n",
    "                # Remove holes\n",
    "                polygons[-1] = polygons[-1].difference(polygon)\n",
    "            else:\n",
    "                # Save disjoint polygons\n",
    "                polygons.append(polygon)\n",
    "                levels.append(level)\n",
    "\n",
    "sum_p = polygons[0]\n",
    "for i in range(1, len(polygons)):\n",
    "    sum_p = shapely.union(sum_p, polygons[i])\n",
    "\n",
    "# Plot each polygon and sample points proportional to the lengthscale density of each polygon\n",
    "pts_list = []\n",
    "train_pts = []\n",
    "num_train_pts = 10000\n",
    "for l, p in zip(levels, polygons):\n",
    "    x_ext, y_ext = p.exterior.xy\n",
    "    plt.plot(x_ext, y_ext, c='C0')\n",
    "\n",
    "    for interior in p.interiors:\n",
    "        x_int, y_int = interior.xy\n",
    "        plt.plot(x_int, y_int, color='C0')\n",
    "\n",
    "    c_area = np.pi*((l/2)**2)\n",
    "    size = int(np.ceil(p.area/c_area))*4\n",
    "    pts = pointpats.random.poisson(p, size=size)\n",
    "    t_pts = pointpats.random.poisson(p, size=size*100)\n",
    "\n",
    "    if size == 1:\n",
    "        pts_list.append([pts])\n",
    "    else:\n",
    "        pts_list.append(pts)\n",
    "    train_pts.append(t_pts)\n",
    "\n",
    "pts_list = np.concatenate(pts_list).astype(X_train.dtype)\n",
    "train_pts = np.concatenate(train_pts).astype(X_train.dtype)\n",
    "print(len(pts_list), len(train_pts))\n",
    "plt.scatter(pts_list[:, 0], pts_list[:, 1], s=5, c='r')\n",
    "plt.scatter(train_pts[:, 0], train_pts[:, 1], s=1, c='C0', alpha=0.1)\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55e9573",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = get_method('ContinuousSGP')\n",
    "sp_optimizer = method(\n",
    "    len(pts_list), \n",
    "    train_pts, \n",
    "    kernel,\n",
    "    noise_variance, \n",
    "    X_init=pts_list.astype(X_train.dtype),\n",
    ")\n",
    "\n",
    "# 4. Run the optimization\n",
    "X_sol = sp_optimizer.optimize()\n",
    "X_sol = X_sol.reshape(-1, 2)\n",
    "\n",
    "# Plot each polygon and solution points\n",
    "for l, p in zip(levels, polygons):\n",
    "    x_ext, y_ext = p.exterior.xy\n",
    "    plt.plot(x_ext, y_ext, c='C0')\n",
    "\n",
    "    for interior in p.interiors:\n",
    "        x_int, y_int = interior.xy\n",
    "        plt.plot(x_int, y_int, color='C0')\n",
    "\n",
    "plt.scatter(X_sol[:, 0], X_sol[:, 1], s=5, c='k')\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49244cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sol, _ = model.predict_f(X_sol)\n",
    "_, _, _, model_sol = get_model_params(\n",
    "    X_train=X_sol, y_train=y_sol, \n",
    "    kernel=kernel,\n",
    "    max_steps=0,\n",
    "    return_model=True,\n",
    "    verbose=False)\n",
    "\n",
    "mean, var = model_sol.predict_f(X_train)\n",
    "sol_path, _ = run_tsp(X_sol, time_limit=15)\n",
    "sol_lengthscales = predict_lengthscales(X_sol, lengthscales, kernel)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(10, 5), constrained_layout=True)\n",
    "\n",
    "# First subplot — training data\n",
    "sc1 = axes[0].scatter(X_train[:, 0], X_train[:, 1], c=mean.numpy())\n",
    "axes[0].scatter(X_sol[:, 0], X_sol[:, 1], c='r', s=5)\n",
    "axes[0].plot(sol_path[0][:, 0], sol_path[0][:, 1], c='r')\n",
    "axes[0].set_title(\"Sol GP Predictions\")\n",
    "axes[0].set_aspect('equal')\n",
    "\n",
    "# Second subplot — variance\n",
    "sc2 = axes[1].scatter(X_train[:, 0], X_train[:, 1], c=var.numpy())\n",
    "axes[1].scatter(X_sol[:, 0], X_sol[:, 1], c='r', s=5)\n",
    "axes[1].set_title(\"Sol GP Variance\")\n",
    "axes[1].set_aspect('equal')\n",
    "\n",
    "# Fix colorbar size\n",
    "cbar = fig.colorbar(sc2, ax=axes[1], fraction=0.046, pad=0.04)\n",
    "\n",
    "# Third subplot — lengthscale\n",
    "axes[2].scatter(X_test[:, 0], X_test[:, 1], c=lengthscale_preds)\n",
    "axes[2].scatter(X_sol[:, 0], X_sol[:, 1], c='r', s=5)\n",
    "axes[2].set_title(\"Lengthscale Map\")\n",
    "axes[2].set_aspect('equal')\n",
    "\n",
    "for pt, d in zip(X_sol, sol_lengthscales):\n",
    "    circle = patches.Circle(pt, \n",
    "                            d/2, \n",
    "                            edgecolor='k', \n",
    "                            facecolor='w', \n",
    "                            alpha=0.3)\n",
    "    axes[2].add_patch(circle)\n",
    "\n",
    "axes[2].set_xlim(axes[0].get_xlim())\n",
    "axes[2].set_ylim(axes[0].get_ylim())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6725eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "locs = np.array([loc.centroid.coords[0] for loc in sol])\n",
    "X_sol = locs.astype(X_train.dtype)\n",
    "y_sol, _ = model.predict_f(X_sol)\n",
    "_, _, _, model_sol = get_model_params(\n",
    "    X_train=X_sol, y_train=y_sol, \n",
    "    kernel=kernel,\n",
    "    max_steps=0,\n",
    "    return_model=True,\n",
    "    verbose=False)\n",
    "\n",
    "mean, var = model_sol.predict_f(X_train)\n",
    "sol_path = [locs]\n",
    "sol_lengthscales = predict_lengthscales(X_sol, lengthscales, kernel)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(10, 5), constrained_layout=True)\n",
    "\n",
    "# First subplot — training data\n",
    "sc1 = axes[0].scatter(X_train[:, 0], X_train[:, 1], c=mean.numpy())\n",
    "axes[0].scatter(X_sol[:, 0], X_sol[:, 1], c='r', s=5)\n",
    "axes[0].plot(sol_path[0][:, 0], sol_path[0][:, 1], c='r')\n",
    "axes[0].set_title(\"Sol GP Predictions\")\n",
    "axes[0].set_aspect('equal')\n",
    "\n",
    "# Second subplot — variance\n",
    "sc2 = axes[1].scatter(X_train[:, 0], X_train[:, 1], c=var.numpy())\n",
    "axes[1].scatter(X_sol[:, 0], X_sol[:, 1], c='r', s=5)\n",
    "axes[1].set_title(\"Sol GP Variance\")\n",
    "axes[1].set_aspect('equal')\n",
    "\n",
    "# Fix colorbar size\n",
    "cbar = fig.colorbar(sc2, ax=axes[1], fraction=0.046, pad=0.04)\n",
    "\n",
    "# Third subplot — lengthscale\n",
    "axes[2].scatter(X_test[:, 0], X_test[:, 1], c=lengthscale_preds)\n",
    "axes[2].scatter(X_sol[:, 0], X_sol[:, 1], c='r', s=5)\n",
    "axes[2].set_title(\"Lengthscale Map\")\n",
    "axes[2].set_aspect('equal')\n",
    "\n",
    "for pt, d in zip(X_sol, sol_lengthscales):\n",
    "    circle = patches.Circle(pt, \n",
    "                            d/2, \n",
    "                            edgecolor='k', \n",
    "                            facecolor='w', \n",
    "                            alpha=0.2)\n",
    "    axes[2].add_patch(circle)\n",
    "\n",
    "axes[2].set_xlim(axes[0].get_xlim())\n",
    "axes[2].set_ylim(axes[0].get_ylim())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703773a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "from shapely.ops import unary_union as union_all\n",
    "\n",
    "\n",
    "def coverage_area(polygons, env):\n",
    "    \"\"\"\n",
    "    Get effective coverage area from selected sensing locations.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    polygons : Sequence[shapely.geometry.base.BaseGeometry]\n",
    "        Polygons representing the observable sensing area at each sensing location.\n",
    "    env : shapely.geometry.Polygon\n",
    "        Polygon representing the extent of the environment.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The area of the union of `polygons` clipped to `env`.\n",
    "    \"\"\"\n",
    "    if not polygons:\n",
    "        return 0.0\n",
    "\n",
    "    union_poly = union_all(polygons)\n",
    "    inside = env.intersection(union_poly)\n",
    "    return inside.area\n",
    "\n",
    "\n",
    "class PriorityQueue:\n",
    "    \"\"\"Max-heap implemented via negative priorities on a min-heap.\"\"\"\n",
    "    def __init__(self, indices, gains):\n",
    "        gains = np.asarray(gains, dtype=float)\n",
    "        self.pq = [(-gains[i], int(idx)) for i, idx in enumerate(indices)]\n",
    "        import heapq\n",
    "        heapq.heapify(self.pq)\n",
    "        self._heapq = heapq\n",
    "\n",
    "    def pop(self):\n",
    "        return self._heapq.heappop(self.pq)\n",
    "\n",
    "    def add(self, idx, gain):\n",
    "        self._heapq.heappush(self.pq, (-float(gain), int(idx)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pq)\n",
    "\n",
    "\n",
    "def lazy_greedy_until_coverage(polygons, env, target_fraction,\n",
    "                               n_jobs=-1, max_selections=None):\n",
    "    \"\"\"\n",
    "    Lazy greedy maximization of coverage area until a fraction of the\n",
    "    environment is covered.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    polygons : Sequence[shapely.geometry.Polygon]\n",
    "        One polygon per sensing location.\n",
    "    env : shapely.geometry.Polygon\n",
    "        Environment polygon (coverage is clipped to this).\n",
    "    target_fraction : float\n",
    "        Fraction of the environment area to cover in [0, 1].\n",
    "        The algorithm stops once coverage >= target_fraction * env.area.\n",
    "    n_jobs : int, optional\n",
    "        Number of CPU cores for parallel initialization (-1 = all cores).\n",
    "    max_selections : int or None, optional\n",
    "        Hard cap on the number of selected locations.\n",
    "        If None, defaults to len(polygons).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    selected : list[int]\n",
    "        Indices of selected sensing locations in `polygons`.\n",
    "    gains : list[float]\n",
    "        Marginal coverage gain at each selection step.\n",
    "    final_area : float\n",
    "        Total covered area after stopping.\n",
    "    final_union : shapely.geometry.base.BaseGeometry or None\n",
    "        Union geometry of selected polygons clipped to `env`.\n",
    "        None if nothing was selected.\n",
    "    \"\"\"\n",
    "    n = len(polygons)\n",
    "    idxs = np.arange(n, dtype=int)\n",
    "\n",
    "    if max_selections is None:\n",
    "        max_selections = n\n",
    "\n",
    "    env_area = env.area\n",
    "    if env_area <= 0:\n",
    "        # Degenerate environment; nothing to cover\n",
    "        return [], [], 0.0, None\n",
    "\n",
    "    target_area = target_fraction * env_area\n",
    "\n",
    "    # --------------- Step 1: parallel initialization (A = ∅) ----------\n",
    "    # For A = ∅, gain for y is coverage_area({y}, env)\n",
    "    if n_jobs is None or n_jobs == 1:\n",
    "        init_gains = np.array(\n",
    "            [coverage_area([polygons[i]], env) for i in idxs],\n",
    "            dtype=float,\n",
    "        )\n",
    "    else:\n",
    "        init_gains = np.array(\n",
    "            Parallel(n_jobs=n_jobs)(\n",
    "                delayed(coverage_area)([polygons[i]], env)\n",
    "                for i in idxs\n",
    "            ),\n",
    "            dtype=float,\n",
    "        )\n",
    "\n",
    "    pq = PriorityQueue(idxs, init_gains)\n",
    "\n",
    "    # Selected set bookkeeping\n",
    "    selected_mask = np.zeros(n, dtype=bool)\n",
    "    selected = []\n",
    "    gains = []\n",
    "\n",
    "    # Current union and area of selected set A\n",
    "    current_union = None\n",
    "    current_area = 0.0\n",
    "\n",
    "    # ----------------- Step 2: lazy greedy loop -----------------------\n",
    "    while (current_area < target_area\n",
    "           and len(selected) < max_selections\n",
    "           and len(pq) > 0):\n",
    "\n",
    "        best_gain = float(\"-inf\")\n",
    "        best_idx = None\n",
    "\n",
    "        while True:\n",
    "            if len(pq) == 0:\n",
    "                break\n",
    "\n",
    "            neg_prev_gain, idx = pq.pop()\n",
    "\n",
    "            # Skip if already selected\n",
    "            if selected_mask[idx]:\n",
    "                continue\n",
    "\n",
    "            # If we pop the same index twice within this outer loop,\n",
    "            # then its up-to-date gain is ≥ all others; accept it.\n",
    "            if best_idx == idx:\n",
    "                break\n",
    "\n",
    "            # ---- Recompute true marginal gain given current A ----\n",
    "            poly_y = polygons[idx]\n",
    "            if current_union is None:\n",
    "                new_union = poly_y\n",
    "            else:\n",
    "                new_union = current_union.union(poly_y)\n",
    "\n",
    "            clipped = new_union.intersection(env)\n",
    "            new_area = clipped.area\n",
    "            gain = new_area - current_area\n",
    "\n",
    "            # Push updated gain back into PQ\n",
    "            pq.add(idx, gain)\n",
    "\n",
    "            # Track best candidate this outer iteration\n",
    "            if gain > best_gain:\n",
    "                best_gain = gain\n",
    "                best_idx = idx\n",
    "            elif gain == best_gain and best_gain == 0.0:\n",
    "                # If everything is effectively zero, accept first\n",
    "                best_gain = gain\n",
    "                best_idx = idx\n",
    "                break\n",
    "\n",
    "        if best_idx is None:\n",
    "            # No viable candidates left\n",
    "            break\n",
    "\n",
    "        # ----------------- Commit best selection --------------------\n",
    "        idx = best_idx\n",
    "        poly_y = polygons[idx]\n",
    "\n",
    "        if current_union is None:\n",
    "            current_union = poly_y\n",
    "        else:\n",
    "            current_union = current_union.union(poly_y)\n",
    "\n",
    "        clipped = current_union.intersection(env)\n",
    "        current_union = clipped          # store clipped union\n",
    "        current_area = clipped.area\n",
    "\n",
    "        selected_mask[idx] = True\n",
    "        selected.append(idx)\n",
    "        gains.append(best_gain)\n",
    "\n",
    "        # Optional: early numerical-stop if additional gain is negligible\n",
    "        if current_area >= target_area:\n",
    "            break\n",
    "\n",
    "    return selected, gains, current_area, current_union\n",
    "\n",
    "\n",
    "selected_idxs, gains, total_area, union_geom = lazy_greedy_until_coverage(\n",
    "    polygons=candidates,\n",
    "    env=env,\n",
    "    target_fraction=0.99,\n",
    "    n_jobs=-1,  # use all cores for initialization\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd507f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "locs = np.array([loc.centroid.coords[0] for loc in np.array(candidates)[selected_idxs]])\n",
    "X_sol = locs.astype(X_train.dtype)\n",
    "y_sol, _ = model.predict_f(X_sol)\n",
    "_, _, _, model_sol = get_model_params(\n",
    "    X_train=X_sol, y_train=y_sol, \n",
    "    kernel=kernel,\n",
    "    max_steps=0,\n",
    "    return_model=True,\n",
    "    verbose=False)\n",
    "\n",
    "mean, var = model_sol.predict_f(X_train)\n",
    "sol_path, _ = run_tsp(X_sol, time_limit=20)\n",
    "sol_lengthscales = predict_lengthscales(X_sol, lengthscales, kernel)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(10, 5), constrained_layout=True)\n",
    "\n",
    "# First subplot — training data\n",
    "sc1 = axes[0].scatter(X_train[:, 0], X_train[:, 1], c=mean.numpy())\n",
    "axes[0].scatter(X_sol[:, 0], X_sol[:, 1], c='r', s=5)\n",
    "axes[0].plot(sol_path[0][:, 0], sol_path[0][:, 1], c='r')\n",
    "axes[0].set_title(\"Sol GP Predictions\")\n",
    "axes[0].set_aspect('equal')\n",
    "\n",
    "# Second subplot — variance\n",
    "sc2 = axes[1].scatter(X_train[:, 0], X_train[:, 1], c=var.numpy())\n",
    "axes[1].scatter(X_sol[:, 0], X_sol[:, 1], c='r', s=5)\n",
    "axes[1].set_title(\"Sol GP Variance\")\n",
    "axes[1].set_aspect('equal')\n",
    "\n",
    "# Fix colorbar size\n",
    "cbar = fig.colorbar(sc2, ax=axes[1], fraction=0.046, pad=0.04)\n",
    "\n",
    "# Third subplot — lengthscale\n",
    "axes[2].scatter(X_test[:, 0], X_test[:, 1], c=lengthscale_preds)\n",
    "axes[2].scatter(X_sol[:, 0], X_sol[:, 1], c='r', s=5)\n",
    "axes[2].set_title(\"Lengthscale Map\")\n",
    "axes[2].set_aspect('equal')\n",
    "\n",
    "for pt, d in zip(X_sol, sol_lengthscales):\n",
    "    circle = patches.Circle(pt, \n",
    "                            d/2, \n",
    "                            edgecolor='k', \n",
    "                            facecolor='w', \n",
    "                            alpha=0.2)\n",
    "    axes[2].add_patch(circle)\n",
    "\n",
    "axes[2].set_xlim(axes[0].get_xlim())\n",
    "axes[2].set_ylim(axes[0].get_ylim())\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
