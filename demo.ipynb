{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff215a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Polygon as MplPolygon\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['text.usetex'] = True\n",
    "\n",
    "from time import time\n",
    "\n",
    "import numpy as np \n",
    "np.random.seed(1234)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "import gpflow\n",
    "gpflow.config.set_default_float(np.float32)\n",
    "gpflow.config.set_default_jitter(1e-2)\n",
    "\n",
    "from sgptools.methods import *\n",
    "from sgptools.kernels import get_kernel\n",
    "from sgptools.utils.tsp import *\n",
    "from sgptools.utils.misc import *\n",
    "from sgptools.utils.metrics import *\n",
    "from sgptools.utils.data import Dataset\n",
    "from sgptools.utils.gpflow import get_model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438ee21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grid(X_data, num_x, num_y):\n",
    "    grid_x, grid_y = np.mgrid[min(X_data[:, 0]):max(X_data[:, 0]):complex(num_x), \n",
    "                              min(X_data[:, 1]):max(X_data[:, 1]):complex(num_y)]\n",
    "    X_grid = np.stack([grid_x, grid_y], axis=-1)\n",
    "    return X_grid.reshape(-1, 2).astype(X_data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d331b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "num_initial = 350\n",
    "data = np.load(\"N17E073.npy\")\n",
    "\n",
    "# Get dataset\n",
    "dataset = Dataset(data=data, dtype=np.float32,\n",
    "                  num_train=5000)\n",
    "del data\n",
    "X_train, y_train = dataset.get_train()\n",
    "\n",
    "# Generate X_init\n",
    "X_init = get_inducing_pts(X_train, num_inducing=15)\n",
    "X_init, _ = run_tsp(X_init)\n",
    "X_init = X_init[0]\n",
    "X_init = resample_path(X_init, num_initial)\n",
    "X_init = X_init.astype(X_train.dtype)\n",
    "X_init, y_init = dataset.get_sensor_data(X_init,\n",
    "                                         max_samples=len(X_init))\n",
    "print(\"Init Set Dims:\", X_init.shape)\n",
    "\n",
    "# Generate X_test\n",
    "x_dim, y_dim = 100, 100\n",
    "X_grid = get_grid(X_train, x_dim, y_dim)\n",
    "X_grid, y_grid = dataset.get_sensor_data(X_grid,\n",
    "                                         max_samples=len(X_grid))\n",
    "print(\"Grid Set Dims:\", X_grid.shape)\n",
    "\n",
    "# Get the extent for potting\n",
    "extent = [min(X_train[:, 0]), max(X_train[:, 0]), \n",
    "          min(X_train[:, 1]), max(X_train[:, 1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46264437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get lengthscales\n",
    "_, noise_variance, kernel = get_model_params(\n",
    "    X_train=X_train, y_train=y_train, \n",
    "    kernel=get_kernel('Attentive')(np.linspace(1, 10, 10)),\n",
    "    optimizer='tf.Nadam',\n",
    "    learning_rate=1e-2,\n",
    "    max_steps=1000,\n",
    "    verbose=True)\n",
    "ls_grid = kernel.get_lengthscales(X_grid)\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4), constrained_layout=True)\n",
    "\n",
    "# First subplot — training data\n",
    "sc1 = axes[0].imshow(y_grid.reshape(x_dim, y_dim).T,\n",
    "                     extent=extent, origin=\"lower\")\n",
    "axes[0].set_title(\"Ground Truth\")\n",
    "axes[0].set_aspect('equal')\n",
    "axes[0].set_xlabel('X')\n",
    "axes[0].set_ylabel('Y')\n",
    "\n",
    "# Second subplot — test data\n",
    "sc2 = axes[1].imshow(ls_grid.reshape(x_dim, y_dim).T, \n",
    "                     extent=extent, origin=\"lower\")\n",
    "axes[1].set_title(\"Lengthscale Predictions\")\n",
    "axes[1].set_aspect('equal')\n",
    "axes[1].set_xlabel('X')\n",
    "axes[1].set_ylabel('Y')\n",
    "\n",
    "# Shared colorbar\n",
    "fig.colorbar(sc2, ax=axes, orientation='vertical', \n",
    "             fraction=0.05, pad=0.04, label='Lengthscale')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e9ff46",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = 'Attentive'\n",
    "target_var_ratio = 0.5\n",
    "\n",
    "if kernel == 'Attentive':\n",
    "    _, noise_variance, kernel, init_model = get_model_params(\n",
    "        X_train=X_init, y_train=y_init, \n",
    "        kernel=get_kernel('Attentive')(np.linspace(1, 10, 10)),\n",
    "        optimizer='tf.Nadam',\n",
    "        learning_rate=1e-2,\n",
    "        max_steps=1000,\n",
    "        return_model=True,\n",
    "        verbose=True)\n",
    "else:\n",
    "    _, noise_variance, kernel, init_model = get_model_params(\n",
    "        X_train=X_init, y_train=y_init, \n",
    "        kernel=get_kernel('RBF')(),\n",
    "        return_model=True,\n",
    "        verbose=True)\n",
    "\n",
    "max_prior_var = init_model.predict_f(X_grid)[1].numpy().max()\n",
    "var_threshold = max_prior_var * target_var_ratio\n",
    "\n",
    "for method in ['HexCoverage', 'GreedyCoverage', 'GCBCoverage']:\n",
    "    cmodel = get_method(method)(num_sensing=len(X_train),\n",
    "                                X_objective=X_train,\n",
    "                                kernel=kernel,\n",
    "                                noise_variance=noise_variance)\n",
    "    s_time = time()\n",
    "    X_sol, fovs = cmodel.optimize(var_threshold=var_threshold, \n",
    "                                  return_fovs=True,\n",
    "                                  start_nodes=X_init[None, -1])\n",
    "    X_sol = X_sol[0]\n",
    "    run_time = time()-s_time\n",
    "\n",
    "    X_pred, y_pred = dataset.get_sensor_data(X_sol,\n",
    "                                             max_samples=len(X_sol))\n",
    "    _, _, _, model_sol = get_model_params(\n",
    "        X_train=np.vstack([X_init, X_pred]), \n",
    "        y_train=np.vstack([y_init, y_pred]), \n",
    "        kernel=kernel,\n",
    "        noise_variance=noise_variance,\n",
    "        max_steps=0,\n",
    "        return_model=True,\n",
    "        verbose=False,\n",
    "        force_gp=True)\n",
    "    mean, var = model_sol.predict_f(X_grid)\n",
    "    distance = get_distance(X_sol)\n",
    "    mse_e = get_mse(mean.numpy(), y_grid)\n",
    "    smse_e = get_smse(mean.numpy(), y_grid, var.numpy())\n",
    "    max_post_var = model_sol.predict_f(X_train)[1].numpy().max()\n",
    "\n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(13, 4.5), constrained_layout=True)\n",
    "\n",
    "    # First subplot — training data\n",
    "    sc1 = axes[0].imshow(mean.numpy().reshape(x_dim, y_dim).T, \n",
    "                         extent=extent, origin=\"lower\")\n",
    "    axes[0].set_title(\"Solution GP Predictions\")\n",
    "    axes[0].set_aspect('equal')\n",
    "    axes[0].set_xlabel('X')\n",
    "    axes[0].set_ylabel('Y')\n",
    "\n",
    "    # Second subplot — Variance data\n",
    "    sc2 = axes[1].imshow(var.numpy().reshape(x_dim, y_dim).T, \n",
    "                        extent=extent, origin=\"lower\")\n",
    "    axes[1].scatter(X_sol[:, 0], X_sol[:, 1], c='r', s=25)\n",
    "    axes[1].plot(X_init[:, 0], X_init[:, 1], c='tab:orange')\n",
    "    axes[1].plot(X_sol[:, 0], X_sol[:, 1], c='r')\n",
    "    axes[1].set_title(\"Solution GP Variance\")\n",
    "    axes[1].set_aspect('equal')\n",
    "    axes[1].set_xlabel('X')\n",
    "    axes[1].set_ylabel('Y')\n",
    "    fig.colorbar(sc2, ax=axes[1], orientation='vertical', \n",
    "                fraction=0.05, pad=0.04, label='Variance')\n",
    "\n",
    "    # Third subplot — FoV data\n",
    "    axes[2].scatter(X_sol[:, 0], X_sol[:, 1], c='r', s=5)\n",
    "    for fov in fovs:\n",
    "        patch = MplPolygon(list(fov.exterior.coords), \n",
    "                        closed=True, \n",
    "                        facecolor='k', \n",
    "                        edgecolor='k', \n",
    "                        alpha=0.3)\n",
    "        axes[2].add_patch(patch)\n",
    "        axes[2].scatter(X_sol[:, 0], X_sol[:, 1], c='r', s=5)\n",
    "    axes[2].set_title(\"Solution FoVs\")\n",
    "    axes[2].set_aspect('equal')\n",
    "    axes[2].set_xlabel('X')\n",
    "    axes[2].set_ylabel('Y')\n",
    "    axes[2].set_xlim(axes[1].get_xlim())\n",
    "    axes[2].set_ylim(axes[1].get_ylim())\n",
    "    \n",
    "    fig.suptitle(f\"{method}; Num Placements: {len(fovs)}; Max Prior Var: {max_prior_var:.2f}; Target Var: {var_threshold:.2f}; Max Posterior Var: {max_post_var:.2f}; MSE: {mse_e:.2f}; SMSE: {smse_e:.2f}; Runtime: {run_time:.2f} s; Distance: {distance:.0f} m\", fontsize=14)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
